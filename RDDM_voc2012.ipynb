{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from src.denoising_diffusion_pytorch import GaussianDiffusion\n",
    "from src.residual_denoising_diffusion_pytorch import (ResidualDiffusion,\n",
    "                                                      Trainer, Unet, UnetRes,\n",
    "                                                      set_seed)\n",
    "\n",
    "# init \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in [0])\n",
    "sys.stdout.flush()\n",
    "set_seed(10)\n",
    "debug = False\n",
    "if debug:\n",
    "    save_and_sample_every = 2\n",
    "    sampling_timesteps = 10\n",
    "    sampling_timesteps_original_ddim_ddpm = 10\n",
    "    train_num_steps = 200\n",
    "else:\n",
    "    save_and_sample_every = 1000\n",
    "    sampling_timesteps = 5\n",
    "    sampling_timesteps_original_ddim_ddpm = 250\n",
    "    train_num_steps = 30000\n",
    "\n",
    "original_ddim_ddpm = False\n",
    "if original_ddim_ddpm:\n",
    "    condition = False\n",
    "    input_condition = False\n",
    "    input_condition_mask = False\n",
    "else:\n",
    "    condition = True\n",
    "    input_condition = True \n",
    "    input_condition_mask = True\n",
    "\n",
    "if condition:\n",
    "    if input_condition:\n",
    "        folder = [\"/home/sss/python/dataset/VOC2012_ORI/train/gt\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/train/fs\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/train/wsobel\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/gt\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/fs\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/wsobel\"\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/gt_256\",\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/FS_256\",\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/wSobel_256\"\n",
    "                ]\n",
    "    else:\n",
    "        folder = [\"/home/sss/python/dataset/Celebrity Face Image Dataset/train/gt\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/train/input_ht_rgb\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/gt\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/input_ht_rgb\"]\n",
    "    train_batch_size = 1\n",
    "    num_samples = 1\n",
    "    sum_scale = 1\n",
    "    image_size = 256\n",
    "else:\n",
    "    folder = '/home/sss/python/dataset/CelebA/img_align_celeba'\n",
    "    train_batch_size = 32\n",
    "    num_samples = 25\n",
    "    sum_scale = 1\n",
    "    image_size = 32\n",
    "\n",
    "if original_ddim_ddpm:\n",
    "    model = Unet(\n",
    "        dim = 64,\n",
    "        dim_mults = (1, 2, 4, 8)\n",
    "    )\n",
    "    diffusion = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=image_size,\n",
    "        timesteps=1000,           # number of steps\n",
    "        sampling_timesteps=sampling_timesteps_original_ddim_ddpm,\n",
    "        loss_type='l1',            # L1 or L2\n",
    "    )\n",
    "else:\n",
    "    model = UnetRes(\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        share_encoder=0, #1 0 -1，分别对应共享编码器、两个独立的 U-Net 和一个独立的 U-Net。\n",
    "        condition=condition,\n",
    "        input_condition=input_condition\n",
    "    )\n",
    "    diffusion = ResidualDiffusion(\n",
    "        model,\n",
    "        image_size=image_size,\n",
    "        timesteps=1000,           # number of steps\n",
    "        # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "        sampling_timesteps=sampling_timesteps,\n",
    "        objective='pred_res_noise', # pred_res_noise, pred_res, pred_noise\n",
    "        loss_type='l1',            # L1 or L2 or huber(SmoothL1)\n",
    "        condition=condition,\n",
    "        sum_scale = sum_scale,\n",
    "        input_condition=input_condition,\n",
    "        input_condition_mask=input_condition_mask\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    folder,\n",
    "    train_batch_size=train_batch_size,\n",
    "    num_samples=num_samples,\n",
    "    train_lr=8e-5,\n",
    "    train_num_steps=train_num_steps,         # total training steps\n",
    "    gradient_accumulate_every=2,    # gradient accumulation steps\n",
    "    ema_decay=0.995,                # exponential moving average decay\n",
    "    amp=False,                        # turn on mixed precision\n",
    "    convert_image_to=\"RGB\",\n",
    "    condition=condition,\n",
    "    save_and_sample_every=save_and_sample_every,\n",
    "    equalizeHist=False,\n",
    "    crop_patch=False,\n",
    "    generation = False,\n",
    "    gaussian_filter = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "#trainer.load(30)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from src.denoising_diffusion_pytorch import GaussianDiffusion\n",
    "from src.residual_denoising_diffusion_pytorch import (ResidualDiffusion,\n",
    "                                                      Trainer, Unet, UnetRes,\n",
    "                                                      set_seed)\n",
    "\n",
    "# init \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in [0])\n",
    "sys.stdout.flush()\n",
    "set_seed(10)\n",
    "debug = False\n",
    "if debug:\n",
    "    save_and_sample_every = 2\n",
    "    sampling_timesteps = 10\n",
    "    sampling_timesteps_original_ddim_ddpm = 10\n",
    "    train_num_steps = 200\n",
    "else:\n",
    "    save_and_sample_every = 1000\n",
    "    sampling_timesteps = 5\n",
    "    sampling_timesteps_original_ddim_ddpm = 250\n",
    "    train_num_steps = 30000\n",
    "\n",
    "original_ddim_ddpm = False\n",
    "if original_ddim_ddpm:\n",
    "    condition = False\n",
    "    input_condition = False\n",
    "    input_condition_mask = False\n",
    "else:\n",
    "    condition = True\n",
    "    input_condition = True \n",
    "    input_condition_mask = True\n",
    "\n",
    "if condition:\n",
    "    if input_condition:\n",
    "        folder = [\"/home/sss/python/dataset/VOC2012_ORI/train/gt\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/train/evcs\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/train/wsobel\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/gt\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/evcs\",\n",
    "                \"/home/sss/python/dataset/VOC2012_ORI/valid/wsobel\"\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/gt_256\",\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/FS_256\",\n",
    "                # \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/wSobel_256\"\n",
    "                ]\n",
    "    else:\n",
    "        folder = [\"/home/sss/python/dataset/Celebrity Face Image Dataset/train/gt\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/train/input_ht_rgb\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/gt\",\n",
    "                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/input_ht_rgb\"]\n",
    "    train_batch_size = 1\n",
    "    num_samples = 1\n",
    "    sum_scale = 1\n",
    "    image_size = 256\n",
    "else:\n",
    "    folder = '/home/sss/python/dataset/CelebA/img_align_celeba'\n",
    "    train_batch_size = 32\n",
    "    num_samples = 25\n",
    "    sum_scale = 1\n",
    "    image_size = 32\n",
    "\n",
    "if original_ddim_ddpm:\n",
    "    model = Unet(\n",
    "        dim = 64,\n",
    "        dim_mults = (1, 2, 4, 8)\n",
    "    )\n",
    "    diffusion = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=image_size,\n",
    "        timesteps=1000,           # number of steps\n",
    "        sampling_timesteps=sampling_timesteps_original_ddim_ddpm,\n",
    "        loss_type='l1',            # L1 or L2\n",
    "    )\n",
    "else:\n",
    "    model = UnetRes(\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        share_encoder=0, #1 0 -1，分别对应共享编码器、两个独立的 U-Net 和一个独立的 U-Net。\n",
    "        condition=condition,\n",
    "        input_condition=input_condition\n",
    "    )\n",
    "    diffusion = ResidualDiffusion(\n",
    "        model,\n",
    "        image_size=image_size,\n",
    "        timesteps=1000,           # number of steps\n",
    "        # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "        sampling_timesteps=sampling_timesteps,\n",
    "        objective='pred_res_noise', # pred_res_noise, pred_res, pred_noise\n",
    "        loss_type='l1',            # L1 or L2 or huber(SmoothL1)\n",
    "        condition=condition,\n",
    "        sum_scale = sum_scale,\n",
    "        input_condition=input_condition,\n",
    "        input_condition_mask=input_condition_mask\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    folder,\n",
    "    train_batch_size=train_batch_size,\n",
    "    num_samples=num_samples,\n",
    "    train_lr=8e-5,\n",
    "    train_num_steps=train_num_steps,         # total training steps\n",
    "    gradient_accumulate_every=2,    # gradient accumulation steps\n",
    "    ema_decay=0.995,                # exponential moving average decay\n",
    "    amp=False,                        # turn on mixed precision\n",
    "    convert_image_to=\"RGB\",\n",
    "    condition=condition,\n",
    "    save_and_sample_every=save_and_sample_every,\n",
    "    equalizeHist=False,\n",
    "    crop_patch=False,\n",
    "    generation = False,\n",
    "    halftone = None,  # fs, evcs, gmevcs\n",
    "    gaussian_filter = True,\n",
    "    get_sobel = None,  # None, sobel, canny, wsobel\n",
    ")\n",
    "\n",
    "if not trainer.accelerator.is_local_main_process:\n",
    "    pass\n",
    "else:\n",
    "    trainer.load(30)\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "if not trainer.accelerator.is_local_main_process:\n",
    "    pass\n",
    "else:\n",
    "    #trainer.load(trainer.train_num_steps//save_and_sample_every)\n",
    "    epoch = 30\n",
    "    trainer.load(epoch)\n",
    "    trainer.set_results_folder(f'./results/DiffSo_FS_Gaussian_ts{sampling_timesteps}_ep{epoch}_wSoRGB')\n",
    "    trainer.test(last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
