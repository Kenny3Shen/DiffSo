{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mair.hub import load_pretrained\n",
    "from mair.attacks import PGD\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "def get_image_files_sample(path, min_lim=20):\n",
    "    files = get_image_files(path)\n",
    "    label_func = parent_label\n",
    "    label_to_files = defaultdict(list)\n",
    "    for file in files:\n",
    "        label = label_func(file)\n",
    "        label_to_files[label].append(file)\n",
    "    sampled_files = []\n",
    "    for files in label_to_files.values():\n",
    "        if len(files) < min_lim:\n",
    "            continue\n",
    "        sampled_files.extend(files)\n",
    "    return sampled_files\n",
    "\n",
    "\n",
    "def label_func(fn):\n",
    "    return (\n",
    "        Path(\"/kaggle/input/lfw-ht/lfw-yt/kaggle/input/lfw-yt\")\n",
    "        / fn.parent.stem\n",
    "        / fn.name.replace(\"png\", \"jpg\")\n",
    "    )\n",
    "\n",
    "\n",
    "class RestoreMax(Transform):\n",
    "    order = 6\n",
    "\n",
    "    def encodes(self, o: TensorImage):\n",
    "        if o.max() == 1:\n",
    "            return o * 255\n",
    "        return o\n",
    "\n",
    "\n",
    "def clean_accuracy(pred, targs):\n",
    "    return attack_learn.pred_clean\n",
    "\n",
    "\n",
    "def legitimate_accuracy(pred, targs):\n",
    "    return attack_learn.pred_legitimate\n",
    "\n",
    "\n",
    "def ht(adv_images):\n",
    "    for x, y in np.ndindex(adv_images.shape[:2]):\n",
    "        img = Image.fromarray(img_as_ubyte(to_np(adv_images[x, y])))\n",
    "        adv_images[x, y] = tensor(img_as_float(img.convert(\"1\")))\n",
    "    adv_images = learn.model(adv_images)[2] * 0.5 + 0.5\n",
    "\n",
    "\n",
    "def rand_att_cb(cb, xb, yb):\n",
    "    if not cb.learn.training:\n",
    "        imgs = xb[0]\n",
    "        pred = cb.model(imgs)\n",
    "        cb.learn.pred_legitimate = accuracy(pred, yb[0])\n",
    "        ht(imgs)\n",
    "        pred = cb.model(imgs)\n",
    "        cb.learn.pred_clean = accuracy(pred, yb[0])\n",
    "    x_adv = xb[0]\n",
    "    with torch.enable_grad():\n",
    "        adv_images = attack(TensorBase(xb[0]), TensorBase(yb[0]))\n",
    "        ht(adv_images)\n",
    "    return (adv_images,), yb\n",
    "\n",
    "\n",
    "def get_resnet18(num_classes):\n",
    "    model = models.resnet18(pretrained=False)  # Do not load pre-trained weights\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "    )  # Change input channels to 1\n",
    "    model.fc = nn.Linear(\n",
    "        model.fc.in_features, num_classes\n",
    "    )  # Adjust the final layer for the number of classes\n",
    "    return model\n",
    "\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n",
    "    get_items=get_image_files_sample,\n",
    "    splitter=RandomSplitter(seed=43, valid_pct=0.1),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=[CropPad(256), RestoreMax],\n",
    ")\n",
    "loaders = data.dataloaders(\"/kaggle/input/lfw-ht/lfw-yt/kaggle/input/lfw-yt\", bs=bs)\n",
    "clean_model = get_resnet18(len(loaders.vocab))\n",
    "clean_model = torch.nn.DataParallel(clean_model.cuda())\n",
    "attack_learn = Learner(\n",
    "    loaders,\n",
    "    clean_model,\n",
    "    metrics=[accuracy, clean_accuracy, legitimate_accuracy],\n",
    "    #               cbs=[before_batch_cb(rand_att_cb)],\n",
    ").to_fp16()\n",
    "attack = PGD(attack_learn.model)\n",
    "attack_learn.fit_one_cycle(200, cbs=[before_batch_cb(rand_att_cb)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cu124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
